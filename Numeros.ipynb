{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "57f75946-7663-4d39-9e27-969326c33acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "import io\n",
    "import tkinter as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37a4852c-840a-4fbe-946a-598325588f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "dataset, metadata = tfds.load('mnist', as_supervised=True, with_info=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "class_names = [\n",
    "    'Cero', 'Uno', 'Dos', 'Tres', 'Cuatro', 'Cinco', 'Seis',\n",
    "    'Siete', 'Ocho', 'Nueve'\n",
    "]\n",
    "\n",
    "num_train_examples = metadata.splits['train'].num_examples\n",
    "num_test_examples = metadata.splits['test'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64ec0933-d8da-4f16-b562-5bee7386104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizar: Numeros de 0 a 255, que sean de 0 a 1\n",
    "def normalize(images, labels):\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    images /= 255\n",
    "    return images, labels\n",
    "\n",
    "train_dataset = train_dataset.map(normalize)\n",
    "test_dataset = test_dataset.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae99cea9-d805-4cf7-af9b-b2f26043c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),  # Regularización\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b59c5019-7a61-4e31-a430-bab966c04187",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2cdcafc9-5534-4f9e-9e61-317ce0cf759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indicar las funciones a utilizar\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27369729-aeac-48e2-9ac6-ed98be6619ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aprendizaje por lotes de 32 cada lote\n",
    "BATCHSIZE = 32\n",
    "train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCHSIZE)\n",
    "test_dataset = test_dataset.batch(BATCHSIZE)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    patience=3,  # Detener si no mejora en 3 épocas\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6423d964-87eb-4e24-9671-ca0b63c5590b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8485 - loss: 0.4944 - val_accuracy: 0.9555 - val_loss: 0.1429\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9515 - loss: 0.1571 - val_accuracy: 0.9640 - val_loss: 0.1119\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.1199 - val_accuracy: 0.9717 - val_loss: 0.0911\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9697 - loss: 0.0993 - val_accuracy: 0.9751 - val_loss: 0.0798\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9721 - loss: 0.0858 - val_accuracy: 0.9758 - val_loss: 0.0878\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9753 - loss: 0.0783 - val_accuracy: 0.9778 - val_loss: 0.0784\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0748 - val_accuracy: 0.9765 - val_loss: 0.0825\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0662 - val_accuracy: 0.9787 - val_loss: 0.0754\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0576 - val_accuracy: 0.9790 - val_loss: 0.0771\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0612 - val_accuracy: 0.9805 - val_loss: 0.0775\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.0511 - val_accuracy: 0.9807 - val_loss: 0.0725\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0529 - val_accuracy: 0.9805 - val_loss: 0.0728\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0484 - val_accuracy: 0.9808 - val_loss: 0.0739\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.0472 - val_accuracy: 0.9797 - val_loss: 0.0791\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0488 - val_accuracy: 0.9818 - val_loss: 0.0774\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0440 - val_accuracy: 0.9833 - val_loss: 0.0733\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0417 - val_accuracy: 0.9811 - val_loss: 0.0730\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.0431 - val_accuracy: 0.9841 - val_loss: 0.0718\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0365 - val_accuracy: 0.9825 - val_loss: 0.0733\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.0373 - val_accuracy: 0.9804 - val_loss: 0.0854\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0629\n",
      "\n",
      "🎯 Precisión en el conjunto de prueba: 98.41%\n",
      "Resultado en las pruebas:  0.9840999841690063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=20,  # Más épocas\n",
    "    steps_per_epoch=math.ceil(metadata.splits['train'].num_examples / BATCHSIZE),\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=math.ceil(metadata.splits['test'].num_examples / BATCHSIZE),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"\\n Precisión en el conjunto de prueba: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"Resultado en las pruebas: \", test_accuracy)\n",
    "for test_images, test_labels in test_dataset.take(1):\n",
    "\ttest_images = test_images.numpy()\n",
    "\ttest_labels = test_labels.numpy()\n",
    "\tpredictions = model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a9f0eecc-9fdc-484c-ac23-7f0ba531b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    }
   ],
   "source": [
    "class AplicacionDibujo:\n",
    "    def __init__(self, modelo):\n",
    "        self.ventana = tk.Tk()\n",
    "        self.ventana.title(\"Dibuja un número (0-9)\")\n",
    "\n",
    "        self.ancho_canvas = 200\n",
    "        self.alto_canvas = 200\n",
    "        self.canvas = tk.Canvas(self.ventana, width=self.ancho_canvas, height=self.alto_canvas, bg='white')\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.boton_predecir = tk.Button(self.ventana, text=\"Predecir\", command=self.predecir_numero)\n",
    "        self.boton_predecir.pack()\n",
    "\n",
    "        self.boton_limpiar = tk.Button(self.ventana, text=\"Limpiar\", command=self.limpiar_canvas)\n",
    "        self.boton_limpiar.pack()\n",
    "\n",
    "        self.etiqueta_resultado = tk.Label(self.ventana, text=\"\", font=(\"Helvetica\", 16))\n",
    "        self.etiqueta_resultado.pack()\n",
    "\n",
    "        self.modelo = modelo\n",
    "\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.dibujar)\n",
    "        self.imagen = Image.new(\"L\", (self.ancho_canvas, self.alto_canvas), 255)\n",
    "        self.dibujo_imagen = ImageDraw.Draw(self.imagen)\n",
    "\n",
    "    def dibujar(self, evento):\n",
    "        x, y = evento.x, evento.y\n",
    "        radio = 8  # grosor del trazo\n",
    "        self.canvas.create_oval(x - radio, y - radio, x + radio, y + radio, fill='black', outline='black')\n",
    "        self.dibujo_imagen.ellipse([x - radio, y - radio, x + radio, y + radio], fill='black')\n",
    "\n",
    "    def limpiar_canvas(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.dibujo_imagen.rectangle([0, 0, self.ancho_canvas, self.alto_canvas], fill='white')\n",
    "        self.etiqueta_resultado.config(text=\"\")\n",
    "\n",
    "    def preprocesar_imagen(self):\n",
    "        # Convertir a 28x28, invertir colores\n",
    "        imagen_redimensionada = self.imagen.resize((28, 28))\n",
    "        imagen_invertida = ImageOps.invert(imagen_redimensionada)\n",
    "\n",
    "        # Mejorar contraste\n",
    "        imagen_invertida = ImageOps.autocontrast(imagen_invertida)\n",
    "\n",
    "        # Convertir a array numpy\n",
    "        imagen_array = np.array(imagen_invertida)\n",
    "\n",
    "        # Eliminar ruido\n",
    "        imagen_array = np.where(imagen_array > 50, imagen_array, 0)\n",
    "\n",
    "        # Centrar la imagen\n",
    "        coordenadas = np.column_stack(np.where(imagen_array > 0))\n",
    "        if coordenadas.size:\n",
    "            y0, x0 = coordenadas.min(axis=0)\n",
    "            y1, x1 = coordenadas.max(axis=0)\n",
    "            imagen_array = imagen_array[y0:y1 + 1, x0:x1 + 1]\n",
    "\n",
    "        # Redimensionar a 20x20 y centrar en 28x28\n",
    "        imagen_pil = Image.fromarray(imagen_array).resize((20, 20), Image.LANCZOS)\n",
    "        imagen_centrada = Image.new('L', (28, 28), 0)\n",
    "        imagen_centrada.paste(imagen_pil, ((28 - 20) // 2, (28 - 20) // 2))\n",
    "\n",
    "        # Normalizar\n",
    "        imagen_array = np.array(imagen_centrada).astype(np.float32) / 255.0\n",
    "        imagen_array = imagen_array.reshape(1, 28, 28, 1)\n",
    "\n",
    "        return imagen_array\n",
    "\n",
    "    def predecir_numero(self):\n",
    "        imagen_procesada = self.preprocesar_imagen()\n",
    "        prediccion = self.modelo.predict(imagen_procesada)\n",
    "\n",
    "        etiqueta = np.argmax(prediccion)\n",
    "        confianza = prediccion[0][etiqueta]\n",
    "        self.etiqueta_resultado.config(text=f\"Predicción: {class_names[etiqueta]} ({confianza * 100:.2f}%)\")\n",
    "\n",
    "    def ejecutar(self):\n",
    "        self.ventana.mainloop()\n",
    "\n",
    "\n",
    "# Lanzar la aplicación\n",
    "app = AplicacionDibujo(model)\n",
    "app.ejecutar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf8446bd-c64f-4ff8-b011-0c4a985bd7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"modelo_mnist.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2427fe87-07e9-4026-b677-7ae77f36a81c",
   "metadata": {},
   "source": [
    "#esto lo vamos a usar en anaconda prompt\n",
    "(base) C:\\Users\\carlo>cd Red_Neuronal_01\n",
    "\n",
    "(base) C:\\Users\\carlo\\Red_neuronal_01>uvicorn main:app --reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67772a12-c4be-441a-8736-0b691e8dd116",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
